{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from shapely.geometry import Point\n",
    "import plotly.express as px\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to extract data from netcdf files\n",
    "\n",
    "\n",
    "def get_variable_from_netcfd(df, lon, lat, var):\n",
    "    \"\"\"Extract variable from netcdf file and interpolate to 30 min intervals\"\"\"\n",
    "    return (\n",
    "        df[var]\n",
    "        .sel(longitude=lon, latitude=lat, method=\"nearest\")\n",
    "        .to_dataframe()\n",
    "        .set_index(\"valid_time\")[[var]]\n",
    "        .resample(\"1800s\")\n",
    "        .interpolate()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ssrd_from_netcfd(df, lon, lat):\n",
    "    _ssrd = get_variable_from_netcfd(df, lon, lat, \"ssrd\")\n",
    "    _ssrd[\"radiation\"] = (_ssrd[\"ssrd\"] - _ssrd[\"ssrd\"].shift(1)).clip(lower=0)\n",
    "    _ssrd[\"radiation\"] = _ssrd[\"radiation\"].fillna(0)\n",
    "    return _ssrd[[\"radiation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "training = pd.read_csv(\"data/training_data.csv\")[[\"dtm\", \"solar_generation_MW\"]]\n",
    "training[\"valid_time\"] = pd.to_datetime(training[\"dtm\"])\n",
    "training = training.drop(columns=[\"dtm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "\n",
    "nwp = xr.load_dataset(\"data/hres_1day_south_scotland_202101_202306.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_variables = [\"t2m\", \"d2m\", \"lcc\", \"mcc\", \"hcc\", \"tp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create range of 4 latitudes and 4 longitudes\n",
    "# from the maximum and minimum values of the NWP data\n",
    "\n",
    "lat_range = np.linspace(\n",
    "    nwp.latitude.values.tolist()[0], nwp.latitude.values.tolist()[-1], 4\n",
    ")\n",
    "lon_range = np.linspace(nwp.longitude.min(), nwp.longitude.max(), 4)\n",
    "\n",
    "lat_range = nwp.latitude.values.tolist()\n",
    "lon_range = nwp.longitude.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotland_gdf = gpd.read_file(\"lad.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_array = np.array(np.meshgrid(lat_range, lon_range)).T.reshape(-1, 2)\n",
    "points = [Point(lon, lat) for lat, lon in cross_array]\n",
    "# Inside Merge\n",
    "inside_points = [point for point in points if scotland_gdf.contains(point).any()]\n",
    "inside_array = np.array([[point.y, point.x] for point in inside_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssrd = pd.DataFrame()\n",
    "\n",
    "for lat, lon in inside_array:\n",
    "    weather = get_ssrd_from_netcfd(nwp, lon, lat)\n",
    "    weather[\"latitude\"] = round(lat, 1)\n",
    "    weather[\"longitude\"] = round(lon, 2)\n",
    "    ssrd = pd.concat([ssrd, weather])\n",
    "\n",
    "ssrd = ssrd.reset_index()\n",
    "ssrd[\"valid_time\"] = ssrd[\"valid_time\"].dt.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = pd.DataFrame()\n",
    "# for lat, lon in inside_array:\n",
    "#     weather = get_variable_from_netcfd(nwp, lon, lat, \"t2m\")\n",
    "#     weather[\"latitude\"] = round(lat, 1)\n",
    "#     weather[\"longitude\"] = round(lon, 2)\n",
    "#     temperature = pd.concat([temperature, weather])\n",
    "\n",
    "# temperature = temperature.reset_index()\n",
    "# temperature[\"valid_time\"] = temperature[\"valid_time\"].dt.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = pd.DataFrame()\n",
    "for lat, lon in inside_array:\n",
    "    weather = get_variable_from_netcfd(nwp, lon, lat, \"lcc\")\n",
    "    weather[\"latitude\"] = round(lat, 1)\n",
    "    weather[\"longitude\"] = round(lon, 2)\n",
    "    cloud = pd.concat([cloud, weather])\n",
    "\n",
    "cloud = cloud.reset_index()\n",
    "cloud[\"valid_time\"] = cloud[\"valid_time\"].dt.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lcc = cloud.groupby(\"valid_time\")['lcc'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merge_radiation = ssrd.merge(training, on=\"valid_time\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_radiation = all_merge_radiation[all_merge_radiation[\"solar_generation_MW\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_radiation = all_merge_radiation[all_merge_radiation[\"solar_generation_MW\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_radiation.sample(1000).plot(\n",
    "#     x=\"radiation\", y=\"solar_generation_MW\", kind=\"scatter\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = (\n",
    "    pd.DataFrame(\n",
    "        training_radiation.groupby(by=[\"latitude\", \"longitude\"])[\n",
    "            [\"solar_generation_MW\", \"radiation\"]\n",
    "        ]\n",
    "        .corr(method = 'pearson')\n",
    "        .iloc[0::2, -1]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(columns=[\"level_2\"])\n",
    "    .rename(columns={\"radiation\": \"correlation\"})\n",
    ")\n",
    "\n",
    "correlations[\"correlation\"].hist(bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = nwp.latitude.values.tolist()\n",
    "longitudes = nwp.longitude.values.tolist()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scotland_gpd_df = gpd.read_file(\"lad.json\")\n",
    "scotland_plot = scotland_gpd_df.plot(ax=ax)\n",
    "scotland_plot.set_xlim(-8, -1.5)\n",
    "scotland_plot.set_ylim(54, 60)\n",
    "\n",
    "\n",
    "rect = Rectangle(\n",
    "    (nwp.longitude.min() - 0.05, nwp.latitude.min() - 0.05),\n",
    "    (nwp.longitude.max() - nwp.longitude.min()) + 0.1,\n",
    "    nwp.latitude.max() - nwp.latitude.min() + 0.1,\n",
    "    linewidth=1,\n",
    "    edgecolor=\"r\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "\n",
    "scotland_plot.scatter(\n",
    "    correlations[\"longitude\"],\n",
    "    correlations[\"latitude\"],\n",
    "    c=correlations[\"correlation\"],\n",
    "    s=50,\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "ax.set_ylim(54.5, 56.6)\n",
    "ax.set_xlim(-6, -1.8)\n",
    "\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Using one location\n",
    "# select_location = (\n",
    "#     correlations.sort_values(by=\"correlation\", ascending=False)\n",
    "#     .head(1)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# select_latitude = select_location[\"latitude\"][0]\n",
    "# select_longitude = select_location[\"longitude\"][0]\n",
    "\n",
    "# select_location_df = training_radiation[\n",
    "#     (training_radiation[\"latitude\"] == select_latitude)\n",
    "#     & (training_radiation[\"longitude\"] == select_longitude)\n",
    "# ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using a few locations with higher correlation\n",
    "\n",
    "# Fraction = 10%\n",
    "\n",
    "select_locations = (\n",
    "    correlations.sort_values(by=\"correlation\", ascending=False)\n",
    "    .head(int(len(correlations) * 0.5))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Filter by selection locations\n",
    "_select_location_df = (\n",
    "    training_radiation.merge(\n",
    "        select_locations, on=[\"latitude\", \"longitude\"], how=\"inner\"\n",
    "    )\n",
    "    # .merge(temperature, on=[\"latitude\", \"longitude\", \"valid_time\"], how=\"inner\")\n",
    "    .groupby(by=[\"valid_time\", \"latitude\", \"longitude\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "select_location_df = _select_location_df.groupby(by=[\"valid_time\"]).mean().reset_index()[['valid_time','radiation','solar_generation_MW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_location_df = (\n",
    "    submission_radiation.merge(\n",
    "        select_locations, on=[\"latitude\", \"longitude\"], how=\"inner\"\n",
    "    )\n",
    "    .groupby(by=[\"valid_time\", \"latitude\", \"longitude\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ").drop(columns=[\"solar_generation_MW\",'correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge average cloud cover\n",
    "# select_location_df = select_location_df.merge(lcc, on=['valid_time'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Addition features\n",
    "\n",
    "# select_location_df[\"days_since_start_of_year\"] = select_location_df[\n",
    "#     \"valid_time\"\n",
    "# ].dt.dayofyear\n",
    "# select_location_df[\"half_hour\"] = (\n",
    "#     select_location_df[\"valid_time\"].dt.hour * 2\n",
    "#     + select_location_df[\"valid_time\"].dt.minute / 30\n",
    "# )\n",
    "\n",
    "\n",
    "# select_location_df[\"sin_days\"] = np.sin(\n",
    "#     2 * np.pi * select_location_df[\"days_since_start_of_year\"] / 365\n",
    "# )\n",
    "# select_location_df[\"cos_days\"] = np.cos(\n",
    "#     2 * np.pi * select_location_df[\"days_since_start_of_year\"] / 365\n",
    "# )\n",
    "# select_location_df[\"sin_hh\"] = np.sin(2 * np.pi * select_location_df[\"half_hour\"] / 48)\n",
    "# select_location_df[\"cos_hh\"] = np.cos(2 * np.pi * select_location_df[\"half_hour\"] / 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    Ridge,\n",
    "    Lasso,\n",
    "    ElasticNet,\n",
    "    BayesianRidge,\n",
    "    HuberRegressor,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [select_location_df, submission_location_df]:\n",
    "    # Adding lagged features\n",
    "    df[\"radiation_lag_-1\"] = df[\"radiation\"].shift(-1)\n",
    "    df[\"radiation_lag_1\"] =  df[\"radiation\"].shift(1)\n",
    "    df[\"radiation_lag_2\"] =  df[\"radiation\"].shift(2)\n",
    "    df[\"radiation_lag_-2\"] = df[\"radiation\"].shift(-2)\n",
    "    df[\"radiation_lag_3\"] =  df[\"radiation\"].shift(3)\n",
    "    df[\"radiation_lag_-3\"] = df[\"radiation\"].shift(-3)\n",
    "    df[\"radiation_lag_4\"] =  df[\"radiation\"].shift(4)\n",
    "    df[\"radiation_lag_-4\"] = df[\"radiation\"].shift(-4)\n",
    "    df[\"radiation_lag_5\"] =  df[\"radiation\"].shift(5)\n",
    "    df[\"radiation_lag_-5\"] = df[\"radiation\"].shift(-5)\n",
    "    df[\"radiation_lag_6\"] =  df[\"radiation\"].shift(6)\n",
    "    df[\"radiation_lag_-6\"] = df[\"radiation\"].shift(-6)\n",
    "\n",
    "select_location_df = select_location_df.fillna(0)\n",
    "submission_location_df = submission_location_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"radiation\",\n",
    "    # \"t2m\",\n",
    "    # \"days_since_start_of_year\",\n",
    "    # \"half_hour\",\n",
    "    # \"sin_days\",\n",
    "    # \"cos_days\",\n",
    "    # \"sin_hh\",\n",
    "    # \"cos_hh\",\n",
    "    # \"lcc\",\n",
    "\n",
    "    \"radiation_lag_1\",\n",
    "    \"radiation_lag_-1\",\n",
    "\n",
    "    # # \"lcc_lag_1\",\n",
    "    # # \"lcc_lag_-1\",    \n",
    "    \"radiation_lag_3\",\n",
    "    \"radiation_lag_-3\",\n",
    "\n",
    "    \"radiation_lag_5\",\n",
    "    \"radiation_lag_-5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_pre = select_location_df[selected_features].fillna(0)\n",
    "# X = scaler.fit_transform(X_pre) \n",
    "# y = select_location_df[\"solar_generation_MW\"]\n",
    "\n",
    "X = select_location_df[selected_features].fillna(0)\n",
    "y = select_location_df[\"solar_generation_MW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = LinearRegression()\n",
    "ridge_pipeline = Ridge()\n",
    "lasso_pipeline = Lasso()\n",
    "elastic_pipeline = ElasticNet()\n",
    "bayesian_pipeline = BayesianRidge()\n",
    "huber_pipeline = HuberRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=6)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "# for train_index, test_index in tss.split(X):\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "set_index = 0 \n",
    "for idx, model in enumerate([\n",
    "    lr_pipeline,\n",
    "    # ridge_pipeline,\n",
    "    huber_pipeline,]):\n",
    "    mae = []\n",
    "    \n",
    "    indexes = {}\n",
    "    train_index_counter = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        indexes[train_index_counter] = train_index\n",
    "\n",
    "\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "\n",
    "        mae.append(mean_absolute_error(y_test, y_pred))\n",
    "        train_index_counter += 1\n",
    "\n",
    "    model_dict[idx] = {\n",
    "        \"model\": model,\n",
    "        \"mae\": round(np.mean(mae),2),\n",
    "        # location of minimum mae in the list of mae\n",
    "        \"best\": np.argmin(mae),\n",
    "        \"best_index\": indexes[np.argmin(mae)],\n",
    "\n",
    "    }\n",
    "    set_index += 1\n",
    "    print(round(np.mean(mae),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = model_dict[1][\"model\"]\n",
    "train_index = model_dict[1][\"best_index\"]\n",
    "\n",
    "chosen_train_data_X = X.iloc[train_index]\n",
    "chosen_train_data_y = y.iloc[train_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model.fit(chosen_train_data_X, chosen_train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_location_df['lr_prediction'] = lr_pipeline.predict(select_location_df[selected_features])\n",
    "select_location_df['lr_prediction'] = select_location_df['lr_prediction'].clip(lower=0)\n",
    "# select_location_df['ridge_prediction'] = ridge_pipeline.predict(select_location_df[selected_features])\n",
    "# select_location_df['ridge_prediction'] = select_location_df['ridge_prediction'].clip(lower=0)\n",
    "select_location_df['huber_prediction'] = huber_pipeline.predict(select_location_df[selected_features])\n",
    "select_location_df['huber_prediction'] = select_location_df['huber_prediction'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_location_df.huber_prediction.sum()/select_location_df.solar_generation_MW.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_location_df.head(20590).tail(50)[['solar_generation_MW','huber_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = select_location_df[['valid_time', 'solar_generation_MW','huber_prediction','radiation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty['date'] = uncertainty['valid_time'].dt.date\n",
    "uncertainty['delta'] = uncertainty['solar_generation_MW'] - uncertainty['huber_prediction']\n",
    "uncertainty['error'] = 100 * ( uncertainty['delta'] / uncertainty['solar_generation_MW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty.groupby(by = ['date'])['delta'].sum().reset_index().sort_values('delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty['days_since_start_of_year'] = pd.to_datetime(uncertainty['date']).dt.dayofyear\n",
    "uncertainty['month'] = pd.to_datetime(uncertainty['date']).dt.month\n",
    "uncertainty['cos_days'] = np.sin(2 * np.pi * uncertainty[\"days_since_start_of_year\"] / 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(uncertainty.sample(10000), x='radiation', y = 'delta', color='month', color_continuous_scale=px.colors.cyclical.Twilight)\n",
    "fig.update_layout(\n",
    "    title=\"Forecast Delta vs Forecast Irradiance\",\n",
    "    xaxis_title=\"Irradiance\",\n",
    "    yaxis_title=\"Delta - MW\",\n",
    "    legend_title=\"Month\",\n",
    "    \n",
    ")\n",
    "# x axis range\n",
    "fig.update_yaxes(range=[-140, 140])\n",
    "fig.update_layout(width = 1000, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(uncertainty.sample(10000).query(\"error < 100\"), x='radiation', y = 'error', color='month', color_continuous_scale=px.colors.cyclical.Twilight)\n",
    "fig.update_layout(\n",
    "    title=\"Forecast Error vs Forecast Irradiance\",\n",
    "    xaxis_title=\"Irradiance\",\n",
    "    yaxis_title=\"Error - %\",\n",
    "    legend_title=\"Month\",\n",
    "    \n",
    ")\n",
    "# x axis range\n",
    "fig.update_yaxes(range=[-140, 140])\n",
    "fig.update_layout(width = 1000, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_number = (dt.date(2023,3,6) - dt.date(2022,1,1)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp['cc'] = nwp['lcc'] + nwp['mcc'] + nwp['hcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Gif\n",
    "\n",
    "for n in range(1, 24):\n",
    "    (nwp[\"ssrd\"].isel(time=day_number, step=n) - nwp[\"ssrd\"].isel(time=day_number, step=0)).plot() \n",
    "    plt.savefig(f\"{n}_pic.png\")\n",
    "    plt.clf()\n",
    "\n",
    "for n in range(1, 24):\n",
    "    (nwp[\"cc\"].isel(time=day_number, step=n) - nwp[\"ssrd\"].isel(time=day_number, step=0)).plot() \n",
    "    plt.savefig(f\"{n}_pic.png\")\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(uncertainty.sample(10000).query(\"error < 100\"), x='solar_generation_MW', y = 'error', color='month', color_continuous_scale=px.colors.cyclical.Twilight)\n",
    "fig.update_layout(\n",
    "    title=\"Forecast Error vs Forecast Irradiance\",\n",
    "    xaxis_title=\"Irradiance\",\n",
    "    yaxis_title=\"Error - %\",\n",
    "    legend_title=\"Month\",\n",
    "    \n",
    ")\n",
    "# x axis range\n",
    "fig.update_yaxes(range=[-140, 140])\n",
    "fig.update_layout(width = 1000, height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(select_location_df, x='valid_time', y=['huber_prediction','solar_generation_MW'])\n",
    "        \n",
    "fig.update_traces(opacity=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission_location_df[['valid_time']].drop_duplicates().reset_index(drop = True)\n",
    "submission_location_df_X = submission_location_df.drop(columns = ['latitude','longitude']).groupby('valid_time').mean()[selected_features]\n",
    "submission['huber_prediction'] = chosen_model.predict(submission_location_df_X)\n",
    "submission['huber_prediction'] = submission['huber_prediction'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(8000).tail(100).plot(x='valid_time', y=['huber_prediction'], kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = pd.read_csv('data/submission_data_[TEAM_NAME].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission['solar_generation_MW'] = submission['huber_prediction']\n",
    "final_submission['solar_generation_MW'] = final_submission['solar_generation_MW'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('bf_solar_forecast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
